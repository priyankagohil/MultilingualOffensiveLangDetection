{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Merger.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMxjujHJPGFJIckZGyWSrY6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RLHPlfMhS6--","executionInfo":{"status":"ok","timestamp":1652301067436,"user_tz":240,"elapsed":4354,"user":{"displayName":"CS SixEightyFive","userId":"14553351259188283144"}},"outputId":"730b32c8-3642-4bfb-8ee0-ac516b39f37d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.53)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import sys\n","sys.path.append('/content/drive/My\\ Drive/')\n","\n","%cd /content/drive//My\\ Drive/languageDetection"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rclVigsmTE7L","executionInfo":{"status":"ok","timestamp":1652301699229,"user_tz":240,"elapsed":978,"user":{"displayName":"CS SixEightyFive","userId":"14553351259188283144"}},"outputId":"d7848c8e-d8d3-4dcf-b882-7d954b00499d"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/languageDetection\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import os \n","import numpy as np\n","import torch\n","\n","from torch.utils.data import DataLoader, TensorDataset, SequentialSampler\n","from transformers import BertTokenizer, BertForSequenceClassification"],"metadata":{"id":"TgW8vucrTLCh","executionInfo":{"status":"ok","timestamp":1652301068323,"user_tz":240,"elapsed":23,"user":{"displayName":"CS SixEightyFive","userId":"14553351259188283144"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["langs = ['english', 'danish', 'turkish', 'arabic', 'greek']\n","dataroot = '/content/drive/MyDrive/data/'\n","label_dict = {'english': 0, 'danish': 1, 'turkish':2, 'arabic':3, 'greek':4}\n","\n","test_files = {}\n","li = []\n","\n","#test dataset\n","for lang in langs:\n","    df0 = os.path.join(dataroot, lang, 'test.tsv')\n","    test_files.update({df0:lang})\n","    \n","for filename, lang in test_files.items():\n","    df1 = pd.read_csv(filename, sep='\\t', usecols = list(range(1,3)))\n","    df1['language'] = label_dict[lang]\n","    li.append(df1)\n","\n","frame = pd.concat(li, axis=0, ignore_index = True)\n","df = frame.sample(frac=1).reset_index(drop=True)\n","print(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Opp4W_yMTbcw","executionInfo":{"status":"ok","timestamp":1652301068324,"user_tz":240,"elapsed":22,"user":{"displayName":"CS SixEightyFive","userId":"14553351259188283144"}},"outputId":"c8218898-348b-4b3f-a8ea-a3cd7d05d0f3"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                  tweet subtask_a  language\n","0     S√∂nm√ºyor ate≈üimiz, ama alev alevde yanmƒ±yor   ...       NOT         2\n","1     @USER Ben dokuz senedir b√∂yle ya≈üƒ±yorum gayet ...       NOT         2\n","2                     ÿ£ÿ®Ÿàÿ∏ÿ®Ÿä Ÿäÿß ÿ¥ÿßŸÖÿÆÿ© Ÿäÿß ÿØÿßÿ± ÿßŸÑÿ£ÿ≥ŸäÿßÿØ ‚ù§Ô∏è       NOT         3\n","3     RT @USER: ÿØŸá ÿ¥ŸÜŸà ÿØŸá Ÿäÿß ÿ¥ÿπÿ® Ÿäÿß ŸÇÿßÿ≥Ÿä Ÿäÿ±ÿ∂ŸäŸÉŸÖ ÿßŸÑÿ≠ÿß...       NOT         3\n","4     ÿ®ŸÉÿ±ÿß ÿπŸÜÿØŸä ÿßÿÆÿ™ÿ®ÿßÿ± ŸÖŸàÿ™ Ÿàÿ≠ŸäÿßŸá Ÿäÿß ÿßŸÜÿ¨ÿ≠ Ÿäÿß ÿßÿ≠ŸÖŸÑ ÿßŸÑŸÖ...       NOT         3\n","...                                                 ...       ...       ...\n","8070  ƒ∞≈üsiz olduƒüun halde ebeveynlerin seni zorla uy...       NOT         2\n","8071  Angels now have 6 runs. Five of them have come...       NOT         0\n","8072  RT @USER: Ÿäÿß ŸÉÿßŸÅÿ± Ÿäÿß ÿ≤ŸÜÿØŸäŸÇ Ÿäÿß ŸÖÿ±ÿ™ÿØ Ÿäÿß<LF>ÿßŸÜÿ™ ÿπ...       OFF         3\n","8073  Sayƒ±n ba≈ükan @USER adana ya denizi getirmi≈üsin...       OFF         2\n","8074  @USER ŒïŒØœáŒ±œÑŒµ œÅœâœÉŒπŒ∫Œ¨ œÄŒøœÖ Œ≠œáŒøœÖŒΩ Œ≥ŒµŒΩŒΩŒÆœÉŒµŒπ œÑŒ∑ ŒºŒ±œÜŒØ...       OFF         4\n","\n","[8075 rows x 3 columns]\n"]}]},{"cell_type":"code","source":["print(len(df[df.language==label_dict['english']]))\n","print(len(df[df.language==label_dict['danish']]))\n","print(len(df[df.language==label_dict['turkish']]))\n","print(len(df[df.language==label_dict['arabic']]))\n","print(len(df[df.language==label_dict['greek']]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AJVGFu1-Ykpp","executionInfo":{"status":"ok","timestamp":1652301068324,"user_tz":240,"elapsed":14,"user":{"displayName":"CS SixEightyFive","userId":"14553351259188283144"}},"outputId":"69b7f11b-0278-432a-b0d4-997be640d29b"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["860\n","329\n","3515\n","1827\n","1544\n"]}]},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n","                                          do_lower_case=True)\n","\n","encoded_data_test = tokenizer.batch_encode_plus(\n","    df.tweet.values, \n","    add_special_tokens=True, \n","    return_attention_mask=True, \n","    pad_to_max_length=True, \n","    max_length=256, \n","    return_tensors='pt'\n",")\n","\n","\n","input_ids_test = encoded_data_test['input_ids']\n","attention_masks_test = encoded_data_test['attention_mask']\n","labels_test = torch.tensor(df.language.values.astype(int))\n","\n","dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_bZcKSp9oJO-","executionInfo":{"status":"ok","timestamp":1652301079760,"user_tz":240,"elapsed":11296,"user":{"displayName":"CS SixEightyFive","userId":"14553351259188283144"}},"outputId":"629d43c4-edc0-4e27-9f5a-b45cc4623254"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["batch_size = 3\n","\n","dataloader_test = DataLoader(dataset_test, \n","                              sampler=SequentialSampler(dataset_test), \n","                              batch_size=batch_size)"],"metadata":{"id":"8ZpCG4dtrSWH","executionInfo":{"status":"ok","timestamp":1652301079760,"user_tz":240,"elapsed":20,"user":{"displayName":"CS SixEightyFive","userId":"14553351259188283144"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"eWanzS5DsYA8","executionInfo":{"status":"ok","timestamp":1652301079761,"user_tz":240,"elapsed":19,"user":{"displayName":"CS SixEightyFive","userId":"14553351259188283144"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n","                                                      num_labels=len(label_dict),\n","                                                      output_attentions=False,\n","                                                      output_hidden_states=False)\n","\n","model.to(device)\n","\n","model.load_state_dict(torch.load('finetuned_BERT_epoch_1_trial.model', map_location=torch.device('cpu')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O7L65gQur7gD","executionInfo":{"status":"ok","timestamp":1652301721592,"user_tz":240,"elapsed":5423,"user":{"displayName":"CS SixEightyFive","userId":"14553351259188283144"}},"outputId":"41ab4704-1209-42c2-838a-25aeccc23960"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["def evaluate(dataloader_test):\n","\n","    model.eval()\n","    \n","    loss_test_total = 0\n","    predictions, true_vals = [], []\n","    \n","    for batch in dataloader_test:\n","        \n","        batch = tuple(b.to(device) for b in batch)\n","        \n","        inputs = {'input_ids':      batch[0],\n","                  'attention_mask': batch[1],\n","                  'labels':         batch[2],\n","                 }\n","\n","        with torch.no_grad():        \n","            outputs = model(**inputs)\n","            \n","        loss = outputs[0]\n","        logits = outputs[1]\n","        loss_test_total += loss.item()\n","\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = inputs['labels'].cpu().numpy()\n","        predictions.append(logits)\n","        true_vals.append(label_ids)\n","    \n","    loss_val_avg = loss_test_total/len(dataloader_test) \n","    \n","    predictions = np.concatenate(predictions, axis=0)\n","    true_vals = np.concatenate(true_vals, axis=0)\n","            \n","    return loss_val_avg, predictions, true_vals"],"metadata":{"id":"Be2_8PABrzs3","executionInfo":{"status":"ok","timestamp":1652301729637,"user_tz":240,"elapsed":3,"user":{"displayName":"CS SixEightyFive","userId":"14553351259188283144"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","\n","def f1_score_func(preds, labels):\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return f1_score(labels_flat, preds_flat, average='weighted')\n","\n","def accuracy_per_class(preds, labels):\n","    label_dict_inverse = {v: k for k, v in label_dict.items()}\n","    \n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    # print(preds_flat)\n","    # print(labels_flat)\n","\n","    for label in np.unique(labels_flat):\n","        y_preds = preds_flat[labels_flat==label]\n","        y_true = labels_flat[labels_flat==label]\n","        print(f'Class: {label_dict_inverse[label]}')\n","        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"],"metadata":{"id":"swMoafaFrtTM","executionInfo":{"status":"ok","timestamp":1652301729816,"user_tz":240,"elapsed":2,"user":{"displayName":"CS SixEightyFive","userId":"14553351259188283144"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["_, predictions, true_vals = evaluate(dataloader_test)\n","accuracy_per_class(predictions, true_vals)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZnSGwxqe26HM","executionInfo":{"status":"ok","timestamp":1652301828371,"user_tz":240,"elapsed":74627,"user":{"displayName":"CS SixEightyFive","userId":"14553351259188283144"}},"outputId":"437d88f0-547c-48e0-edbc-9afd3e5408bc"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Class: english\n","Accuracy: 841/860\n","\n","Class: danish\n","Accuracy: 327/329\n","\n","Class: turkish\n","Accuracy: 3510/3515\n","\n","Class: arabic\n","Accuracy: 1827/1827\n","\n","Class: greek\n","Accuracy: 1544/1544\n","\n"]}]},{"cell_type":"code","source":["len(np.argmax(predictions, axis=1).flatten())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oNltV6zS4xxR","executionInfo":{"status":"ok","timestamp":1652301854515,"user_tz":240,"elapsed":163,"user":{"displayName":"CS SixEightyFive","userId":"14553351259188283144"}},"outputId":"68564840-b96b-4e17-ed4c-77109c41149f"},"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8075"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["# label_dict = {'english': 0, 'danish': 1, 'turkish':2, 'arabic':3, 'greek':4}\n","preds_flat = np.argmax(predictions, axis=1).flatten()\n","english_li = []\n","danish_li = []\n","turkish_li = []\n","arabic_li = []\n","greek_li = []\n","\n","count =0\n","for index, row in df.iloc[:, :].iterrows():\n","    if row.language == preds_flat[index]:\n","        row_value = pd.DataFrame({'tweet': [row.tweet], 'subtask_a': row.subtask_a})\n","        if row.language==0:\n","            english_li.append(row_value)\n","        elif row.language==1:\n","            danish_li.append(row_value)\n","        elif row.language==2:\n","            turkish_li.append(row_value)\n","        elif row.language==3:\n","            arabic_li.append(row_value)\n","        elif row.language==4:\n","            greek_li.append(row_value)\n","        else: \n","          pass\n","\n","english_df = pd.concat(english_li, axis=0, ignore_index = True)\n","danish_df = pd.concat(danish_li, axis=0, ignore_index = True)\n","turkish_df = pd.concat(turkish_li, axis=0, ignore_index = True)\n","arabic_df = pd.concat(arabic_li, axis=0, ignore_index = True)\n","greek_df = pd.concat(greek_li, axis=0, ignore_index = True)\n","print(english_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ue0PwNN22Vk5","executionInfo":{"status":"ok","timestamp":1652301868115,"user_tz":240,"elapsed":5157,"user":{"displayName":"CS SixEightyFive","userId":"14553351259188283144"}},"outputId":"d3cbf3a1-6977-4705-a20b-bcbb65eca409"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                 tweet subtask_a\n","0    #TRUMP:  I'd be a real good witness! #JOHNDowd...       NOT\n","1    #Sugardaddy Retweet if you are under 30 and yo...       NOT\n","2    #LiberalHypocrisy #TacoBell When Liberals ask ...       OFF\n","3    #Believe When you have a fat belly then you ar...       NOT\n","4    #Hillary and @ least 16 other #AngryDemocrats ...       OFF\n","..                                                 ...       ...\n","836  #GreatAwakening #QAnon #PatriotsUnited #WWG1WG...       NOT\n","837  #Conservatism101   It's not about our disagree...       OFF\n","838  #CNN ruthlessly continues #Fakenews onslot. Wh...       NOT\n","839  28, 27, 25 and 21 but like,, it‚Äôs still really...       OFF\n","840  Angels now have 6 runs. Five of them have come...       NOT\n","\n","[841 rows x 2 columns]\n"]}]},{"cell_type":"code","source":["%cd /content/drive//My\\ Drive/data1/english"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Olj7uKpjUyPl","executionInfo":{"status":"ok","timestamp":1652301875947,"user_tz":240,"elapsed":144,"user":{"displayName":"CS SixEightyFive","userId":"14553351259188283144"}},"outputId":"a605b06d-c846-4024-fada-83897180ed94"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/data1/english\n"]}]},{"cell_type":"code","source":["#English\n","%cd /content/drive//My\\ Drive/data1/english\n","english_df.to_csv('test.csv')\n","\n","#Danish\n","%cd /content/drive//My\\ Drive/data1/danish\n","danish_df.to_csv('test.csv')\n","\n","#Turkish\n","%cd /content/drive//My\\ Drive/data1/turkish\n","turkish_df.to_csv('test.csv')\n","\n","\n","#Arabic\n","%cd /content/drive//My\\ Drive/data1/arabic\n","arabic_df.to_csv('test.csv')\n","\n","#Greek\n","%cd /content/drive//My\\ Drive/data1/greek\n","greek_df.to_csv('test.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gbA_Iclhrd6V","executionInfo":{"status":"ok","timestamp":1652301880824,"user_tz":240,"elapsed":164,"user":{"displayName":"CS SixEightyFive","userId":"14553351259188283144"}},"outputId":"c4c81f44-6ad5-4d79-ee49-5f711bea5c26"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/data1/english\n","/content/drive/My Drive/data1/danish\n","/content/drive/My Drive/data1/turkish\n","/content/drive/My Drive/data1/arabic\n","/content/drive/My Drive/data1/greek\n"]}]},{"cell_type":"code","source":["%cd /content/drive//My\\ Drive/languageDetection\n","error_list=[]\n","\n","for index, row in df.iloc[:, :].iterrows():\n","    # break\n","    if row.language != preds_flat[index]:\n","        row_value = pd.DataFrame({'tweet': [row.tweet], 'true_label': row.language, 'predicted_label': preds_flat[index]})\n","        error_list.append(row_value)\n","\n","error_df = pd.concat(error_list, axis=0, ignore_index = True)\n","error_df.to_csv('error.csv')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"weK6-i8W4n3g","executionInfo":{"status":"ok","timestamp":1652303235524,"user_tz":240,"elapsed":7657,"user":{"displayName":"CS SixEightyFive","userId":"14553351259188283144"}},"outputId":"eab812fb-1f50-4270-9353-43d0df89beb9"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/languageDetection\n"]}]},{"cell_type":"code","source":["error_df[error_df.true_label != error_df.predicted_label]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z4JoTjsb62jA","executionInfo":{"status":"ok","timestamp":1652303021844,"user_tz":240,"elapsed":255,"user":{"displayName":"CS SixEightyFive","userId":"14553351259188283144"}},"outputId":"bd02aa24-9974-4c8a-b179-27eb1f260452"},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1254                    Didn't work too well, did it? URL\n","1480    *17. Celine_SwittinS Follback Erza_Jullian #Op...\n","1604    0-9 : B-1, J-1, R-1, B-2, Q-2, B-3, BX-3, B-4,...\n","2089           7 fucking years. #MyTwitterAnniversary URL\n","2111    -tsk stays.... Drop foto HAN JISUNG dong, plea...\n","2171                 G√∂ƒüs√ºnde uyumam gereken geceler var.\n","2698             #LisaxMichaelKors  she is soo beautifull\n","2852                   26. Biggest accomplishment? school\n","2885      #ConsTOO THE PLACE FOR FED UP CONSERVATIVES !!!\n","2891    #ALDUBLoveAndBeyond when you rise in life, you...\n","4452    #AntifaHorst - whuuuuut?! üòÇ  #antifa #maassen ...\n","4457    thats why u r lame duck :))       biz desek li...\n","4538    #StopEtchecopar? Fuck you all üñïüñïüñïüñïüñï Que florez...\n","4935    6ix9ine aus den speakern, fick deine political...\n","5046                             @USER ryger du hash. ???\n","5277                                     Bu i≈ü T A M A M.\n","5613                                        5k Bitches üéâüíô\n","5721                        #NICKIDAGOATüò§‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è she is!!!\n","6130            0-8 En Taller : S-2, M-5, BX-6 (20:59:35)\n","6733                       En sevdiƒüim ikili pubg ve priz\n","7042                               *gets all the bitches*\n","7240                                       And dicks. URL\n","7256                                 Anal stimulation URL\n","7552    ...KE≈ûKE HER K√úRT B√ñYLE MEDENƒ∞ K√úLT√úRL√ú OLSA H...\n","7617    *109. Celine_SwittinS Follback Erza_Jullian #O...\n","7690                    ...veer left by the old church...\n","Name: tweet, dtype: object"]},"metadata":{},"execution_count":55}]}]}